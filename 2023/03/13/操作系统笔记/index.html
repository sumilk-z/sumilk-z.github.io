<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="zhu">



    <meta name="description" content="这是一个个人博客">



<title>操作系统相关笔记——进程线程、调度、内存管理、线程调度、锁、IO多路复用 | zcblog</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


<meta name="generator" content="Hexo 5.4.2"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Zhu&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">主页</a>
                
                    <a class="menu-item" href="/category">归档</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Zhu&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">主页</a>
                
                    <a class="menu-item" href="/category">归档</a>
                
                    <a class="menu-item" href="/tag">标签</a>
                
                    <a class="menu-item" href="/about">关于</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">操作系统相关笔记——进程线程、调度、内存管理、线程调度、锁、IO多路复用</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">zhu</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">三月 13, 2023&nbsp;&nbsp;13:00:19</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/basic/">basic</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h4 id="冯诺依曼结构"><a href="#冯诺依曼结构" class="headerlink" title="冯诺依曼结构"></a>冯诺依曼结构</h4><blockquote>
<p> 运算器，控制器，存储器，输入设备和输出设备。</p>
</blockquote>
<p>1 + 2 = 3是如何被CPU执行的：</p>
<p>总线：地址总线，控制总线和数据总线。</p>
<p>常见的寄存器种类：通用寄存器，程序计数寄存器，指令寄存器</p>
<p>线路位宽和CPU位宽，串行</p>
<blockquote>
<p> 指令周期：　 fetch decode execution store</p>
</blockquote>
<p>程序的CPU执行时间 = <strong>CPU 时钟周期数（*CPU Cycles*）和时钟周期时间（*Clock Cycle Time*）的乘积</strong>。</p>
<p><strong>CPU 时钟周期数 = 指令数 x 每条指令的平均时钟周期数（Cycles Per Instruction，简称 <code>CPI</code>）</strong></p>
<h4 id="SRAM和DRAM"><a href="#SRAM和DRAM" class="headerlink" title="SRAM和DRAM"></a>SRAM和DRAM</h4><p>静态随机存储和动态随机存储，前者用做高速缓存，后者用做内存。后者信息存储在电容中，需要动态刷新来保持信息。</p>
<p>SSD solid state disk 固态硬盘</p>
<p>HDD hard disk drive 机械硬盘</p>
<p>CPU Cache 用的是一种叫 <strong>SRAM（*Static Random-Access* Memory，静态随机存储器）</strong> 的芯片。</p>
<p>SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。</p>
<p>内存用的芯片和 CPU Cache 有所不同，它使用的是一种叫作 <strong>DRAM （*Dynamic Random Access Memory*，动态随机存取存储器）</strong> 的芯片。</p>
<blockquote>
<p>Cache用的是SRAM，内存用的是DRAM</p>
</blockquote>
<h4 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h4><p><strong>L1 Cache 通常会分为「数据缓存」和「指令缓存」</strong></p>
<p>L3 Cache 比 L1 Cache 和 L2 Cache 大很多，这是因为 <strong>L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。</strong></p>
<p>程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。</p>
<p>全相联映射：主存中的块在cache中随意放（就是想放cache中的哪一行就放哪一行）</p>
<p>直接映射：主存块号%cache有多少行，通过这样计算出来的结果，就是主存块在cache中存放的位置。</p>
<p>组相连映射：主存块号%cache中有多少组，通过这样计算出来的结果，就是主存块在cache中存放的组，至于在组中可以随意放。</p>
<blockquote>
<p>直接映射：只能放到固定的位置， 主存块号%Cache中有多少行</p>
<p>组相连映射：把cache分组，组内可以随便放。</p>
<p>全相连映射：随便放到cache中的位置，只要有空位置就放</p>
</blockquote>
<p>直接映射：通过<strong>内存地址</strong>找到 CPU Cache 中的数据</p>
<p>如果有效位是0，那么当前cache中该cache line的数据无效，CPU直接从内存中获取数据。</p>
<p>如果是1，说明有效，根据内存地址的索引计算cache中对应的索引位置，例如内存地址大小为32， cache大小为8，我们要找到内存地址编号为15的数据在cache中的位置：只需要计算 15%8 = 7说明在cache中索引为7的块中。然后再检查<strong>组标记是否为15</strong>，如果是则说明是我们需要的数据块，再根据offset找到对应的数据。否则cache命中失效。</p>
<p>cache中的标记位：就是这块cache放的内存数据的实际地址。</p>
<blockquote>
<p>一个内存的访问地址，包括<strong>组标记、CPU Cache Line 索引、偏移量</strong>这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由<strong>索引 + 有效位 + 组标记 + 数据块</strong>组成。</p>
</blockquote>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98/%E7%9B%B4%E6%8E%A5Cache%E6%98%A0%E5%B0%84.png" alt="img"></p>
<p>其他映射方式： 全相连 Cache （<em>Fully Associative Cache</em>）、组相连 Cache （<em>Set Associative Cache</em>）</p>
<p><strong>CPU Cache 的结构</strong>，CPU Cache 是由很多个 Cache Line 组成的，CPU Line 是 CPU 从内存读取数据的基本单位，而 CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="img"></p>
<h4 id="写直达和写回"><a href="#写直达和写回" class="headerlink" title="写直达和写回"></a>写直达和写回</h4><p>把 Cache 中的数据写回到内存</p>
<p><strong>把数据同时写入内存和 Cache 中</strong>，这种方法称为<strong>写直达(write through)</strong></p>
<p>在<strong>写回机制</strong>中，<strong>当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block==「被替换」==时才需要写到内存中</strong>，减少了数据写回内存的频率，这样便可以提高系统的性能。</p>
<h4 id="缓存一致性问题"><a href="#缓存一致性问题" class="headerlink" title="缓存一致性问题"></a>缓存一致性问题</h4><h5 id="缓存一致性问题-1"><a href="#缓存一致性问题-1" class="headerlink" title="缓存一致性问题"></a><strong>缓存一致性问题</strong></h5><p>现在 CPU 都是多核的，由于 L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的<strong>缓存一致性（*Cache Coherence*）</strong> 的问题，如果不能保证缓存一致性的问题，就可能造成结果错误。</p>
<p>某个核心如果对内存数据读取到缓存中，进行了修改，但是使用的是写回方法，没有立即将数据更新到内存中。那么另一个核心读取内存中的相同数据时读取的不是最新数据，导致错误。这就是<strong>缓存一致性</strong>问题。</p>
<ul>
<li><p>第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为<strong>写传播（*Write Propagation*）</strong>；</p>
</li>
<li><p>第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为<strong>事务的串行化（*Transaction Serialization*）</strong>。</p>
<p>要实现事务串行化，要做到 2 点：</p>
<ul>
<li>CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心；</li>
<li>要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新。</li>
</ul>
</li>
</ul>
<p>实现方案：</p>
<h5 id="1-总线嗅探"><a href="#1-总线嗅探" class="headerlink" title="1.总线嗅探"></a><strong>1.总线嗅探</strong></h5><p>当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心，总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串行化。</p>
<h5 id="2-MESI"><a href="#2-MESI" class="headerlink" title="2.MESI"></a><strong>2.MESI</strong></h5><p>MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：</p>
<ul>
<li><em>Modified</em>，已修改</li>
<li><em>Exclusive</em>，独占</li>
<li><em>Shared</em>，共享</li>
<li><em>Invalidated</em>，已失效</li>
</ul>
<p>这四个状态来标记 Cache Line 四个不同的状态</p>
<p>「已修改」状态就是我们前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。</p>
<p>「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。</p>
<p>独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入</p>
<p>【共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。</p>
<p>我们举个具体的例子来看看这四个状态的转换：</p>
<ol>
<li>当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；</li>
<li>然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；</li>
<li>当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。</li>
<li>如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。</li>
<li>如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。</li>
</ol>
<h4 id="CPU是如何执行任务的"><a href="#CPU是如何执行任务的" class="headerlink" title="CPU是如何执行任务的"></a>CPU是如何执行任务的</h4><p>cpu架构图</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/CPU%E6%9E%B6%E6%9E%84.png" alt="img"></p>
<p>CPU 有多个核心，每个核心都有L1 Cache（分为指令cache和数据cache）和L2 Cache, L3 Cache是共享的。</p>
<h4 id="伪共享问题"><a href="#伪共享问题" class="headerlink" title="伪共享问题"></a>伪共享问题</h4><p>这个问题不是问题，不会导致错误，但是会降低CPU性能，原因是cache失效。</p>
<p>因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为<strong>伪共享（*False Sharing*）</strong></p>
<p>描述：两个<strong>变量在同一个cache line</strong>中，两个核心分别操作两个变量，就会导致两个核心会交替地把这个cache line加锁，修改，写回内存； 然后另一个核心再读内存，加锁，修改，写回内存。此时cache完全没有体现其缓存的作用，cache失效。</p>
<blockquote>
<p>因为加锁的基本单位是cache line. 所以导致这个问题。因此，对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，否则就会出现为伪共享的问题。</p>
</blockquote>
<p>解决方案：让变量不连续，而是对齐</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/struct_ab1.png" alt="img"></p>
<p>避免 Cache 伪共享实际上是用空间换时间的思想，浪费一部分 Cache 空间，从而换来性能的提升。</p>
<p>或者是进行填充</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/%E5%A1%AB%E5%85%85%E5%AD%97%E8%8A%82.png" alt="img"></p>
<h4 id="CPU是如何选择线程的（线程调度方法）"><a href="#CPU是如何选择线程的（线程调度方法）" class="headerlink" title="CPU是如何选择线程的（线程调度方法）"></a>CPU是如何选择线程的（线程调度方法）</h4><p>系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。</p>
<p>任务分为实时任务和普通任务，调度方法有：</p>
<p>Deadline 和 Realtime 这两个调度类，都是应用于实时任务的，这两个调度类的调度策略合起来共有这三种，它们的作用如下：</p>
<ul>
<li><em>SCHED_DEADLINE</em>：是<strong>按照 deadline 进行调度</strong>的，距离当前时间点最近的 deadline 的任务会被优先调度；</li>
<li><em>SCHED_FIFO</em>：对于相同优先级的任务，按<strong>先来先服务的原则</strong>，但是优先级更高的任务，可以抢占低优先级的任务，也就是优先级高的可以「插队」；</li>
<li><em>SCHED_RR</em>：对于相同优先级的任务，<strong>轮流着运行</strong>，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，但是高优先级的任务依然可以抢占低优先级的任务；</li>
</ul>
<p>而 Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：</p>
<ul>
<li><em>SCHED_NORMAL</em>：普通任务使用的调度策略；</li>
<li><em>SCHED_BATCH</em>：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。</li>
</ul>
<p>在 Linux 里面，实现了一个基于 CFS 的调度算法，也就是<strong>完全公平调度（*Completely Fair Scheduling*）</strong>。</p>
<p>这个算法的理念是想让分配给每个任务的 CPU 时间是一样，于是它为每个任务安排一个<strong>虚拟运行时间 vruntime</strong>，如果一个任务在运行，其运行的越久，该任务的 vruntime 自然就会越大，而没有被运行的任务，vruntime 是不会变化的。</p>
<p><strong>在 CFS 算法调度的时候，会优先选择 vruntime 少的任务</strong>，以保证每个任务的公平性。</p>
<h4 id="硬中断和软中断"><a href="#硬中断和软中断" class="headerlink" title="硬中断和软中断"></a>硬中断和软中断</h4><p>在计算机中，中断是系统用来<strong>响应硬件设备请求</strong>的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。</p>
<p>中断是一种异步的事件处理机制，可以提高系统的并发处理能力，操作系统收到了中断请求，会打断其他进程的运行，所以<strong>中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度地影响。</strong></p>
<p>那 Linux 系统<strong>为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」</strong>。</p>
<ul>
<li><strong>上半部用来快速处理中断</strong>，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。 （先记录）</li>
<li><strong>下半部用来延迟处理上半部未完成的工作</strong>，一般以「内核线程」的方式运行。（再处理）</li>
</ul>
<blockquote>
<p>中断丢失：在处理一个中断的时候，此时有其他中断，导致其他中断丢失。 （未接电话）</p>
</blockquote>
<p>中断处理程序的上部分和下半部可以理解为：</p>
<ul>
<li><strong>上半部直接处理硬件请求，也就是硬中断</strong>，主要是负责耗时短的工作，特点是快速执行；</li>
<li><strong>下半部是由内核触发，也就说软中断</strong>，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；</li>
</ul>
<p>还有一个区别，硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行</p>
<blockquote>
<ul>
<li>什么是内核线程？</li>
</ul>
</blockquote>
<h4 id="什么是内核线程"><a href="#什么是内核线程" class="headerlink" title="什么是内核线程"></a>什么是内核线程</h4><p><strong>内核线程(kernel-level threads)<strong>指需要内核的参与，</strong>由内核完成线程的调度</strong>。其依赖于操作系统核心，由内核的内部需求进行创建和撤销。内核线程的线程表(thread table)位于内核中，包括了<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E7%BA%BF%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97/3026392?fromModule=lemma_inlink">线程控制块</a>(TCB),一旦线程阻塞，内核会从当前或者其他进程(process)中重新选择一个线程保证程序的执行。</p>
<p>每一个 CPU 都有各自的软中断内核线程，我们还可以用 ps 命令来查看内核线程，一般名字在中括号里面到，都认为是内核线程。</p>
<h4 id="用户空间和内核空间"><a href="#用户空间和内核空间" class="headerlink" title="用户空间和内核空间"></a>用户空间和内核空间</h4><p>现代操作系统，内核一般会提供 4 个基本能力：</p>
<ul>
<li>管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力；</li>
<li>管理内存，决定内存的分配和回收，也就是内存管理的能力；</li>
<li>管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力；</li>
<li>提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。</li>
</ul>
<p>内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域：</p>
<ul>
<li>内核空间，这个内存空间只有<strong>内核程序</strong>可以访问；</li>
<li>用户空间，这个内存空间专门给<strong>应用程序</strong>使用；</li>
</ul>
<p>用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间</p>
<p>当程序使用用户空间时，我们常说该程序在<strong>用户态</strong>执行，而当程序使内核空间时，程序则在<strong>内核态</strong>执行。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E6%A0%B8/systemcall.png" alt="img"></p>
<p>内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，<strong>会产生一个中断</strong>。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。</p>
<blockquote>
<p>用户态和内核态之间的切换会产生中断，应用程序在内核态执行系统调用。</p>
</blockquote>
<h4 id="并发和并行"><a href="#并发和并行" class="headerlink" title="并发和并行"></a><strong>并发和并行</strong></h4><ul>
<li>对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，<strong>一段时间内执行了多个任务，这被称为并发。</strong></li>
<li>对于<strong>多核 CPU</strong> 时，多个任务可以同时<strong>被不同核心的 CPU 同时执行，这被称为并行</strong>。</li>
</ul>
<blockquote>
<p>并行不是一个任务被分割成多个部分同时执行。而是多个任务同时执行。</p>
</blockquote>
<p>当今 Windows 7、Windows 10 使用的内核叫 <strong>Windows NT，NT 全称叫 New Technology</strong>。</p>
<h4 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h4><blockquote>
<p>单片机是没有操作系统的，所以每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来.<strong>单片机的 CPU 是直接操作内存的「物理地址」</strong></p>
</blockquote>
<ul>
<li>我们程序所使用的内存地址叫做<strong>虚拟内存地址</strong>（<em>Virtual Memory Address</em>）</li>
<li>实际存在硬件里面的空间地址叫<strong>物理内存地址</strong>（<em>Physical Memory Address</em>）</li>
</ul>
<h4 id="内存分段和内存分页"><a href="#内存分段和内存分页" class="headerlink" title="内存分段和内存分页"></a>内存分段和内存分页</h4><p>操作系统是如何管理虚拟地址与物理地址之间的关系？</p>
<p>主要有两种方式，分别是<strong>内存分段和内存分页</strong></p>
<p>为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套<strong>虚拟地址空间</strong>，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。</p>
<p>每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过<strong>内存交换</strong>技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。</p>
<p>那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。</p>
<p>那么对于虚拟地址与物理地址的映射关系，可以有<strong>分段</strong>和<strong>分页</strong>的方式，同时两者结合都是可以的。</p>
<p>内存分段是根据程序的逻辑角度，<strong>分成了栈段、堆段、数据段、代码段等</strong>，这样可以分离出不同属性的段，同时<strong>是一块连续的空间</strong>。但是<strong>每个段的大小都不是统一的</strong>，这就会导致外部<strong>内存碎片和内存交换效率低</strong>的问题。</p>
<p>于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 <code>4KB</code>。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。</p>
<p>再来，为了<strong>解决简单分页产生的页表过大</strong>的问题，就有了<strong>多级页表</strong>，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的<strong>局部性原理</strong>，在 CPU 芯片中加入了 <strong>TLB</strong>，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。</p>
<p><strong>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理</strong>。于是 Linux 就把所有段的基地址设为 <code>0</code>，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。</p>
<p>另外，Linux 系统中虚拟空间分布可分为<strong>用户态</strong>和<strong>内核态</strong>两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。</p>
<p>如果不支持重定位，凡是涉及到内存访问的地方都需要将地址硬编码，进而必须把某个程序加载到内存的固定区间。有了分段机制，程序中只需要使用基于段的相对地址，然后更改段基址，就可以方便地对程序进行重定位。</p>
<h4 id="进程的5种基本状态"><a href="#进程的5种基本状态" class="headerlink" title="进程的5种基本状态"></a>进程的5种基本状态</h4><ul>
<li>运行状态（<em>Running</em>）：该时刻进程占用 CPU；</li>
<li>就绪状态（<em>Ready</em>）：可运行，由于其他进程处于运行状态而暂时停止运行；</li>
<li>阻塞状态（<em>Blocked</em>）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而<strong>暂时停止运行</strong>，这时，即使给它CPU控制权，它也无法运行；</li>
</ul>
<p>当然，进程还有另外两个基本状态：</p>
<ul>
<li>创建状态（<em>new</em>）：进程正在被创建时的状态；</li>
<li>结束状态（<em>Exit</em>）：进程正在从系统中消失时的状态</li>
</ul>
<blockquote>
<p>挂起状态：没有占用实际的物理内存，被OS调出去了。</p>
</blockquote>
<p><strong>描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态</strong>。</p>
<p>阻塞状态是不一样，阻塞状态是等待某个事件的返回。</p>
<p>挂起状态可以分为两种：</p>
<ul>
<li>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</li>
<li>就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</li>
</ul>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg" alt="七种状态变迁"></p>
<p>导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p>
<ul>
<li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li>
<li>用户希望挂起一个程序的执行，比如在 Linux 中用 <code>Ctrl+Z</code> 挂起进程；</li>
</ul>
<h4 id="PCB包含的信息"><a href="#PCB包含的信息" class="headerlink" title="PCB包含的信息"></a>PCB包含的信息</h4><p>PCB是一个进程存在的标识，包含的信息有：</p>
<p><strong>进程描述信息：</strong></p>
<ul>
<li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li>
<li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li>
</ul>
<p><strong>进程控制和管理信息：</strong></p>
<ul>
<li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li>
<li>进程优先级：进程抢占 CPU 时的优先级；</li>
</ul>
<p><strong>资源分配清单：</strong></p>
<ul>
<li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。</li>
</ul>
<p><strong>CPU 相关信息：</strong></p>
<ul>
<li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li>
</ul>
<p>通常是通过<strong>链表</strong>的方式进行组织，把具有<strong>相同状态的进程链在一起，组成各种队列</strong>。比如：</p>
<ul>
<li>将所有处于就绪状态的进程链在一起，称为<strong>就绪队列</strong>；</li>
<li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种<strong>阻塞队列</strong>；</li>
<li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li>
</ul>
<p><strong>操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。</strong></p>
<p>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 <code>kill</code> 掉）。</p>
<p>当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的<strong>子进程就变为孤儿进程</strong>，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。</p>
<h4 id="终止进程的过程"><a href="#终止进程的过程" class="headerlink" title="终止进程的过程"></a>终止进程的过程</h4><p>终止进程的过程如下：</p>
<ul>
<li>查找需要终止的进程的 PCB；</li>
<li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li>
<li>如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；</li>
<li>将该进程所拥有的全部资源都归还给操作系统；</li>
<li>将其从 PCB 所在队列中删除；</li>
</ul>
<p><strong>一个进程切换到另一个进程运行，称为进程的上下文切换</strong>。</p>
<blockquote>
<p> 进程是由内核管理和调度的，所以进程的切换只能发生在内核态</p>
</blockquote>
<blockquote>
<p>发生进程上下文切换有哪些场景？</p>
</blockquote>
<ul>
<li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的<strong>时间片耗尽</strong>了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li>
<li>进程在<strong>系统资源不足</strong>（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li>
<li>当进程通过睡眠函数 <strong>sleep</strong> 这样的方法将自己主动挂起时，自然也会重新调度；</li>
<li>当有<strong>优先级更高</strong>的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li>
<li>发生<strong>硬件中断</strong>时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序</li>
</ul>
<blockquote>
<p> 当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒</p>
</blockquote>
<p>阻塞进程的过程如下：</p>
<ul>
<li>找到将要被阻塞进程标识号对应的 PCB；</li>
<li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li>
<li>将该 PCB 插入到阻塞队列中去；</li>
</ul>
<h4 id="线程"><a href="#线程" class="headerlink" title="线程"></a><strong>线程</strong></h4><p>需要有一种新的实体，满足以下特性：</p>
<ul>
<li>实体之间可以<strong>并发运行；</strong></li>
<li>实体之间<strong>共享相同的地址空间；</strong></li>
</ul>
<p>这个新的实体，就是<strong>线程( *Thread* )<strong>，线程之间</strong>可以并发运行且共享相同的地址空间</strong></p>
<h4 id="线程与进程的比较"><a href="#线程与进程的比较" class="headerlink" title="线程与进程的比较"></a>线程与进程的比较</h4><p>线程与进程的比较如下：</p>
<ul>
<li><strong>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位</strong>；</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；</li>
</ul>
<p>对于，线程相比进程能减少开销，体现在：</p>
<ul>
<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>
<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>
<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>
<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>
</ul>
<blockquote>
<p> <strong>线程是调度的基本单位，而进程则是资源拥有的基本单位</strong>。</p>
</blockquote>
<p>主要有三种线程的实现方式：</p>
<ul>
<li><strong>用户线程（*User Thread*）</strong>：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li>
<li><strong>内核线程（*Kernel Thread*）</strong>：在内核中实现的线程，是由内核管理的线程；</li>
<li><strong>轻量级进程（*LightWeight Process*）</strong>：在内核中来支持用户线程；</li>
</ul>
<ul>
<li><strong>非抢占式调度算法</strong>挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li>
<li><strong>抢占式调度算法</strong>挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生<strong>时钟中断</strong>，以便把 CPU 控制返回给调度程序进行调度，也就是常说的<strong>时间片机制</strong>。</li>
</ul>
<h4 id="进程-线程调度算法"><a href="#进程-线程调度算法" class="headerlink" title="进程/线程调度算法"></a>进程/线程调度算法</h4><p>最简单的一个调度算法，就是非抢占式的==<strong>先来先服务（*First Come First Serve, FCFS*）算法</strong>==</p>
<p>这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。</p>
<p>FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。</p>
<p>==<strong>最短作业优先（*Shortest Job First, SJF*）调度算法</strong>==同样也是顾名思义，它会<strong>优先选择运行时间最短的进程来运行</strong>，这有助于提高系统的吞吐量</p>
<p>==<strong>高响应比优先 （*Highest Response Ratio Next, HRRN*）调度算法</strong>==主要是权衡了短作业和长作业。</p>
<p><strong>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行</strong>，「响应比优先级」的计算公式</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg" alt="img"></p>
<ul>
<li>如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；</li>
<li>如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；</li>
</ul>
<blockquote>
<p> 高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的。 optimal</p>
</blockquote>
<p>最古老、最简单、最公平且使用最广的算法就是==<strong>时间片轮转（*Round Robin, RR*）调度算法</strong>。==</p>
<ul>
<li>如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；</li>
<li>如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；</li>
</ul>
<p>另外，时间片的长度就是一个很关键的点：</p>
<ul>
<li>如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；</li>
<li>如果设得太长又可能引起对短作业进程的响应时间变长。将</li>
</ul>
<p>希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为==<strong>最高优先级（Highest Priority First，HPF）调度算法</strong>==</p>
<ul>
<li>非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。</li>
<li>抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。</li>
</ul>
<p>==<strong>多级反馈队列（*Multilevel Feedback Queue*）调度算法</strong>==是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p>
<ul>
<li>「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。</li>
<li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；</li>
</ul>
<h4 id="进程通信方式"><a href="#进程通信方式" class="headerlink" title="进程通信方式"></a>进程通信方式</h4><p>每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核</p>
<h5 id="管道通信"><a href="#管道通信" class="headerlink" title="管道通信"></a><strong>管道通信</strong></h5><blockquote>
<p>类似消息队列. </p>
</blockquote>
<p><strong>所谓的管道，就是内核里面的一串缓存</strong></p>
<p>从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且<strong>大小受限</strong>。</p>
<blockquote>
<p>管道是无格式的字节流数据</p>
</blockquote>
<p>不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循<strong>先进先出</strong>原则</p>
<p>管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据</p>
<blockquote>
<p>在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型. 用户自定义格式的消息体. 管道是字节流</p>
</blockquote>
<h5 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a><strong>消息队列</strong></h5><p><strong>消息队列是保存在内核中的消息链表</strong></p>
<p>消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。</p>
<p><strong>消息队列不适合比较大数据的传输</strong>，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。</p>
<p><strong>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销</strong>，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。</p>
<h5 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a><strong>共享内存</strong></h5><p>每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中</p>
<p><strong>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>,这样这个进程写入的东西，另外一个进程马上就能看到了，</p>
<h6 id="信号量机制"><a href="#信号量机制" class="headerlink" title="信号量机制"></a><strong>信号量</strong>机制</h6><p>用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。</p>
<p><strong>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据</strong></p>
<p><strong>信号量表示资源的数量</strong>，控制信号量的方式有两种原子操作：</p>
<ul>
<li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。</li>
<li>另一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li>
</ul>
<p>P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。</p>
<p>例如: 资源数量为1</p>
<ul>
<li>进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。</li>
<li>若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。</li>
<li>直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。</li>
</ul>
<blockquote>
<p>P V操作都是在最外侧. 例如先进行P操作,判断资源是否可用. 释放资源之后再执行V操作.</p>
</blockquote>
<p><strong>用信号量来实现多进程同步的方式，我们可以初始化信号量为 <code>0</code>。</strong></p>
<ul>
<li>如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，<strong>故信号量会变为 -1，表示进程 A 还没生产数据</strong>，于是进程 B 就阻塞等待；</li>
<li>接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；</li>
<li>最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。</li>
</ul>
<p>B 开始执行的条件为信号量为0,但是A最开始没执行和执行结束之后信号量都是0,如何区分?</p>
<p>答: A执行完之后唤醒阻塞队列中的B,虽然信号量都是0,但是B是被A唤醒的</p>
<blockquote>
<p> 信号初始化为 <code>1</code>，就代表着是<strong>互斥信号量</strong>，信号初始化为 <code>0</code>，就代表着是<strong>同步信号量</strong>，它可以保证进程 A 应在进程 B 之前执行。</p>
</blockquote>
<blockquote>
<p> <strong>信号量不仅可以实现访问的互斥性，还可以实现进程间的同步</strong></p>
</blockquote>
<h5 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h5><p>上面说的进程间通信，都是常规状态下的工作模式。<strong>对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。</strong></p>
<p>信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）</p>
<blockquote>
<p>意思是给进程发信号，例如 kill -9 pid</p>
<p>这里的通信实际上理解为通知更好，因为是软件或者硬件对进程的通知。</p>
</blockquote>
<p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p>
<p><strong>1.执行默认操作</strong>。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</p>
<p><strong>2.捕捉信号</strong>。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</p>
<p><strong>3.忽略信号</strong>。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程</p>
<blockquote>
<p>发送的信号可能是希望进程执行某个操作：例如终止操作，停止操作。</p>
<p>也可能是希望进程处理何种信息</p>
</blockquote>
<h5 id="socket"><a href="#socket" class="headerlink" title="socket"></a><strong>socket</strong></h5><p>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想<strong>跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。</strong></p>
<p>Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。</p>
<blockquote>
<p><strong>要与不同主机的进程间通信，那么就需要 Socket 通信了</strong></p>
</blockquote>
<p><strong>线程间通信</strong></p>
<p>同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以<strong>对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题</strong>，信号量也同样可以在线程间实现互斥与同步：</p>
<ul>
<li>互斥的方式，可保证任意时刻只有一个线程访问共享资源；</li>
<li>同步的方式，可保证线程 A 应在线程 B 之前执行；</li>
</ul>
<h4 id="线程崩溃了，进程也会崩溃么"><a href="#线程崩溃了，进程也会崩溃么" class="headerlink" title="线程崩溃了，进程也会崩溃么"></a>线程崩溃了，进程也会崩溃么</h4><p><strong>为什么 C/C++ 语言里，线程崩溃后，进程也会崩溃，而 Java 语言里却不会呢？</strong></p>
<p>理论上是的，对于一个进程内的所有线程，其中一个线程崩溃，就会导致其他线程崩溃，进而导致整个进程的崩溃。</p>
<p>因为这些线程共享相同的内存空间和资源，<strong>操作系统认为一个线程崩溃，导致资源受到损坏或者污染，干脆让所有线程都崩溃</strong>。</p>
<blockquote>
<p>连坐。</p>
</blockquote>
<p>那么线程崩溃后，进程是如何崩溃的呢，这背后的机制到底是怎样的，答案是<strong>信号</strong>。</p>
<blockquote>
<p>操作系统给相关的进程发送的信号，因为这个进程中的某个线程进行了非法内存访问导致线程崩溃。</p>
</blockquote>
<ul>
<li><p>如果进程没有注册自己的信号处理函数，那么<strong>操作系统会执行默认的信号处理程序（一般最后会让进程退出）</strong>，</p>
</li>
<li><p>如果注册了，则会<strong>执行自己的信号处理函数</strong>，这样的话就给了进程一个垂死挣扎的机会，它收到 kill 信号后，可以调用 exit() 来退出</p>
</li>
</ul>
<p><strong>Java中线程崩溃不会导致进程崩溃的原因是：</strong></p>
<p><strong>JVM 自己定义了信号处理函数</strong>，这样当发送 kill pid 命令（默认会传 15 也就是 SIGTERM）后，JVM 就可以在信号处理函数中执行一些资源清理之后再调用 exit 退出。</p>
<blockquote>
<p>JVM自定义了信号处理函数，所以不会导致进程的崩溃。</p>
</blockquote>
<h4 id="多线程冲突"><a href="#多线程冲突" class="headerlink" title="多线程冲突"></a>多线程冲突</h4><p><strong>临界区（*critical section*），它是访问共享资源的代码片段，一定不能给多线程同时执行。</strong></p>
<p><strong>互斥（*mutualexclusion*）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区</strong></p>
<p><strong>所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步</strong></p>
<h5 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h5><blockquote>
<p>使用加锁操作和解锁操作可以解决并发线程/进程的互斥问题</p>
</blockquote>
<p><strong>锁的两种实现：忙等待锁（自旋锁）， 无等待锁。</strong></p>
<p>自旋锁</p>
<p>TestAndSet方法： 不仅能Set还能返回之前的状态。这是一个原子操作。</p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/13-TestAndSet.jpg" alt="img"></p>
<p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5/14-%E8%87%AA%E6%97%8B%E9%94%81.jpg" alt="img"></p>
<p>自旋锁：在没有获取锁的时候，一直等待。</p>
<blockquote>
<p>关键在这句 TestAndSet(&amp;lock-&gt;flag, 1)==1.</p>
<p>如果此时有另一个线程获取到了锁，那么锁的状态是被设置为1的，TestAndSet操作得到的结果也是1。当前线程无法获取锁，一直在这个while循环中。</p>
<p>如果TestAndSet操作得到的结果是0，说明锁被释放了，当前线程立马获得了锁，并将状态设置为1.</p>
</blockquote>
<p>很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为<strong>自旋锁（*spin lock*）</strong>。</p>
<ul>
<li><strong>无等待锁</strong>顾明思议就是获取不到锁的时候，不用自旋。</li>
</ul>
<p>既然不想自旋，那当没获取到锁的时候，就<strong>把当前线程放入到锁的等待队列</strong>，然后执行调度程序，把 CPU 让给其他线程执行。</p>
<h5 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h5><blockquote>
<p> 一般来说，信号量的值表示资源的数量。例如只有一个共享资源的时候，sem=1</p>
</blockquote>
<blockquote>
<p> 使用信号量来实现进程同步时，信号量的初始值设置为0. sem = 0</p>
</blockquote>
<p><strong>信号量实现互斥</strong></p>
<ul>
<li><em>P 操作</em>：将 <code>sem</code> 减 <code>1</code>，相减后，如果 <code>sem &lt; 0</code>，则进程/线程进入阻塞等待，否则继续</li>
<li><em>V 操作</em>：将 <code>sem</code> 加 <code>1</code>，相加后，如果 <code>sem &lt;= 0</code>，唤醒一个等待中的进程/线程</li>
</ul>
<p><strong>理解：</strong></p>
<p>假设现在仅剩一个资源，sem=1, p操作: sem=0, 资源可用。</p>
<p>没有资源，sem=0, p操作：sem=-1, 资源不可用，说明p操作之后，如果sem&lt;0,那么表示资源不可用，不撤销操作，当前线程对sem进行了操作表明当前线程需要这个资源。</p>
<blockquote>
<p>p操作是：先试探/检测资源是否可用，再进行实际的操作。</p>
</blockquote>
<p>假设现在仅有一个资源，sem=1, 当前线程执行P操纵，sem=0, sem&gt;=0, 当前资源可用，当前线程使用这个资源。</p>
<p>另一个线程也想使用，执行p操作，sem=-1,资源不可用，继续等待。</p>
<p>当前线程资源使用完毕，执行V操作， sem=0, sem&lt;=0说明有别的进程在等待，唤醒等待队列的第一个进程。</p>
<p>假设资源有两个 sem=2</p>
<p>第一个进程： p 操作， sem=1, sem&gt;=0, 资源可用</p>
<p>第二个进程：p操作， sem=0, sem&gt;=0, 资源可用</p>
<p>第三个进程: p 操作， sem=-1,sem&lt;0,资源不可用,阻塞。</p>
<p>第一个进程执行完毕，V 操作， sem=0, sem&lt;=0, 说明有进程在等待，去唤醒。</p>
<p>第二个进程执行完毕，V操作, sem =1, sem &gt; 0, 无进程在等待，结束。</p>
<p>第三个进程被唤醒，此时sem=1. 表示剩余1个资源可用。而他自己本身占用了一个资源。</p>
<blockquote>
<p> PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的</p>
</blockquote>
<p><strong>信号量实现同步</strong></p>
<p>初始时sem=0.假设有AB两个线程，B必须在A线程之后执行。</p>
<p>不论哪个线程，执行之前都要执行P操作。</p>
<p>A执行P操作，sem=-1</p>
<p>B试图执行，执行P操作，sem=-2, 阻塞。</p>
<p>A执行V操作，sem=-1</p>
<h4 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h4><p>死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。</p>
<p>死锁只有同时满足互斥、持有并等待、不可剥夺、环路等待这四个条件的时候才会发生。</p>
<p>那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是<strong>使用资源有序分配法，来破环环路等待条件</strong>。</p>
<p>线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。</p>
<h4 id="互斥锁、自旋锁"><a href="#互斥锁、自旋锁" class="headerlink" title="互斥锁、自旋锁"></a>互斥锁、自旋锁</h4><p>最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的</p>
<ul>
<li><p><strong>互斥锁</strong>加锁失败后，线程会<strong>释放 CPU</strong> ，给其他线程；</p>
<p><strong>释放 CPU后，线程阻塞：对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的</strong></p>
<blockquote>
<p> 互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本</p>
</blockquote>
</li>
<li><p><strong>自旋锁</strong>加锁失败后，线程会<strong>忙等待</strong>，直到它拿到锁；</p>
<blockquote>
<p> 自旋锁，不会主动产生线程上下文切换，自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用</p>
</blockquote>
</li>
</ul>
<p><strong>如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。</strong></p>
<blockquote>
<p>因为互斥锁会导致线程阻塞，阻塞就会从用户态到内核态，得到锁又就绪的时候，又从内核态到用户态，涉及到两次上下文切换，比较耗费时间。</p>
</blockquote>
<p>自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：<strong>当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对</strong>。</p>
<h4 id="读写锁"><a href="#读写锁" class="headerlink" title="读写锁"></a><strong>读写锁</strong></h4><p>读写锁的工作原理是：</p>
<ul>
<li>当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。</li>
<li>但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。</li>
</ul>
<p>写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有</p>
<p>根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」</p>
<ul>
<li><p><strong>读优先锁</strong>： 加了读锁，此时有一个写锁，写锁等待。其他加读锁的也可以继续加，即读优先。</p>
<p>读优先锁对于读线程并发性更好。 但是如果一直有读线程获取读锁，写锁获取不到，造成<strong>写线程饥饿</strong>。</p>
</li>
<li><p><strong>写优先锁</strong>：加了读锁，此时有一个写锁，读锁等待，写锁先执行。其他加读锁的也等待，即写优先。</p>
<p>写优先锁可以保证写线程不会饿死，一直有写线程获取写锁，读线程饥饿。</p>
</li>
<li><p>公平读写锁</p>
<p><strong>用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。</strong></p>
</li>
</ul>
<h4 id="悲观锁、乐观锁"><a href="#悲观锁、乐观锁" class="headerlink" title="悲观锁、乐观锁"></a>悲观锁、乐观锁</h4><p>互斥锁、自旋锁、读写锁，都是属于悲观锁。</p>
<p>悲观锁：先加锁，在执行操作</p>
<p>乐观锁：先执行操作，再检查是否有问题，有问题则撤销操作</p>
<p>乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：<strong>先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作</strong>。</p>
<p>这里举一个场景例子：<strong>在线文档。</strong></p>
<p>我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。</p>
<p>那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。</p>
<p>服务端要怎么验证是否冲突了呢？通常方案如下：</p>
<ul>
<li>由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；</li>
<li>当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。</li>
</ul>
<blockquote>
<p>浏览器会记录服务器返回的版本号，浏览器提交的时候和服务端的最新版本号进行比较，如果不一致则提交失败，表明发生了冲突。</p>
</blockquote>
<p>乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以<strong>只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。</strong></p>
<blockquote>
<p>乐观锁的应用场景：发生冲突的概率比较低的情景。</p>
</blockquote>
<h4 id="调度算法汇总"><a href="#调度算法汇总" class="headerlink" title="调度算法汇总"></a>调度算法汇总</h4><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E6%8F%90%E7%BA%B2.png" alt="本文提纲"></p>
<h5 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h5><p>先来先服务FCFS，最短时间优先，时间片轮转，最高响应比（响应比=（等待时间+要求服务时间）/要求服务时间），最高优先级，多级反馈队列</p>
<p>多级反馈队列</p>
<ul>
<li>「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。</li>
<li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；</li>
</ul>
<h5 id="页面置换算法"><a href="#页面置换算法" class="headerlink" title="页面置换算法"></a>页面置换算法</h5><p>页面置换算法的功能是，<strong>当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面</strong>，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页</p>
<p>什么时候发生页面置换：1.缓存不命中时 2.从磁盘找到对应的数据 3.页面上没有空闲页 4.页面上没有无效页，没有脏页（被修改过）</p>
<p>先进先出，最近最久未使用</p>
<p>==最佳页面置换算法==： <strong>置换在「未来」最长时间不访问的页面</strong>。理想状态，衡量标准。</p>
<p>==先进先出置换算法：FIFO==</p>
<p>==最近最久未使用（*LRU=*）==的置换算法的基本思路是，发生缺页时，<strong>选择最长时间没有被访问的页面进行置换</strong>，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。</p>
<p>==最不常用（<em>LFU</em>）算法==：<strong>当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰</strong>。</p>
<p>LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。</p>
<p>那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率</p>
<p>==时钟页面置换算法==</p>
<p>该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。</p>
<p>当发生缺页中断时，算法首先检查表针指向的页面：</p>
<ul>
<li>如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；</li>
<li>如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；</li>
</ul>
<h5 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h5><p>==先来先服务（<em>First-Come，First-Served，FCFS</em>）==，顾名思义，先到来的请求，先被服务。</p>
<p>如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长</p>
<p>==最短寻道时间优先（*Shortest SeekTime First，SSTF）==算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求</p>
<p>以使每次的寻道时间最短,不能保证平均寻道时间最短，这种算法会产生“饥饿”现象</p>
<p>优先级低的进程会发生“饥饿”现象。因为新进程请求到达，且其所要访问的磁道与磁头当前所在的磁道距离较近，必先优先满足</p>
<p>==SCAN==</p>
<p><strong>磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（*Scan*）算法</strong>。</p>
<p>==循环扫描（<em>Circular Scan, CSCAN</em> ）==规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且<strong>返回中途不处理任何请求</strong>，该算法的特点，就是<strong>磁道只响应一个方向上的请求</strong>。</p>
<p>我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。</p>
<p>那这其实是可以优化的，优化的思路就是<strong>磁头在移动到「最远的请求」位置，然后立即反向移动。</strong></p>
<p>== LOOK 算法==，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中会响应请求</strong>。</p>
<p>而针 C-SCAN 算法的优化则叫 ==C-LOOK==，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中不会响应请求</strong>。</p>
<h4 id="设备管理DMA"><a href="#设备管理DMA" class="headerlink" title="设备管理DMA"></a>设备管理DMA</h4><p>在前面我知道，每种设备都有一个设备控制器，控制器相当于一个小 CPU，它可以自己处理一些事情，但有个问题是，当 CPU 给设备发送了一个指令，让设备控制器去读设备的数据，它读完的时候，要怎么通知 CPU 呢？</p>
<p>控制器的寄存器一般会有状态标记位，用来标识输入或输出操作是否完成。于是，我们想到第一种<strong>轮询等待</strong>的方法，让 CPU 一直查寄存器的状态，直到状态标记为完成，很明显，这种方式非常的傻瓜，它会占用 CPU 的全部时间。</p>
<p>那我们就想到第二种方法 —— <strong>中断</strong>，通知操作系统数据已经准备好了。我们一般会有一个硬件的<strong>中断控制器</strong>，当设备完成任务后触发中断到中断控制器，中断控制器就通知 CPU，一个中断产生了，CPU 需要停下当前手里的事情来处理中断。</p>
<p>另外，中断有两种，一种<strong>软中断</strong>，例如代码调用 <code>INT</code> 指令触发，一种是<strong>硬件中断</strong>，就是硬件通过中断控制器触发的。</p>
<p>但中断的方式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占用 CPU 大量的时间。对于这一类设备的问题的解决方法是使用 ==<strong>DMA（*Direct Memory Access*）</strong>==功能，它可以使得设备在 CPU 不参与的情况下，能够自行完成把设备 I/O 数据放入到内存。那要实现 DMA 功能要有 「DMA 控制器」硬件的支持。</p>
<p>DMA 的工作方式如下：</p>
<ul>
<li><p>CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了；</p>
<blockquote>
<p>CPU 不再对磁盘控制器下达指令，而是给DMA下达指令，告知需要从哪里取数据，取到之后放到哪里。</p>
</blockquote>
</li>
<li><p>接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存；</p>
<blockquote>
<p>DMA代替CPU给磁盘控制器发出指令，磁盘控制器将数据准备好，写入到磁盘控制器的缓冲区中</p>
</blockquote>
</li>
<li><p>磁盘缓冲区的数据写满之后，<strong>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务</strong>；</p>
<blockquote>
<p>DMA继续工作，把缓冲区中的数据写入到内核缓冲区中</p>
</blockquote>
<blockquote>
<p>DMA写完之后发信号给CPU，CPU可以直接使用内核缓冲区中的数据。</p>
</blockquote>
</li>
<li><p>DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了；</p>
</li>
<li><p><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/DRM%20I_O%20%E8%BF%87%E7%A8%8B.png" alt="img"></p>
</li>
</ul>
<p>在没有 DMA 技术前，I/O 的过程是这样的：</p>
<ul>
<li><p>CPU 发出对应的指令给<strong>磁盘控制器</strong>，然后返回；</p>
</li>
<li><p>磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个<strong>中断</strong>；</p>
<blockquote>
<p>磁盘控制器把数据准备好之后（放到缓冲区中），产生一个中断通知CPU</p>
</blockquote>
</li>
<li><p>CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。</p>
<blockquote>
<p>CPU 收到中断信号，把缓冲区中的数据通过寄存器，再写入到内存中。</p>
</blockquote>
</li>
</ul>
<p>什么是 DMA 技术？简单理解就是，<strong>在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务</strong>。</p>
<blockquote>
<p>DMA相当于一个中介，CPU要处理硬件，交给DMA处理，然后CPU去做别的事情，DMA处理好之后再通知CPU。</p>
</blockquote>
<h4 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a>零拷贝技术</h4><p>传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。</p>
<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png" alt="img" style="zoom:80%;">

<p>如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：<strong>将磁盘上的文件读取出来，然后通过网络协议发送给客户端</strong>。</p>
<p>梳理一下：将数据从磁盘文件读取，到写给网卡进行发送的过程中：</p>
<ul>
<li>用户发起read系统调用，从用户态切换到内核态</li>
<li>在内核态，DMA从磁盘读取数据到内核缓冲区中</li>
<li>从内核态切换到用户态，将内核缓冲区中的数据写到用户缓冲区中</li>
<li>接下来是发送过程，用户发起write系统调用</li>
<li>从用户态切换到内核态，将用户缓冲区中的数据写入到socket缓冲区中</li>
<li>通过DMA技术从socket缓冲区中写入到网卡中</li>
<li>然后从内核态中切换回用户态，继续做别的事情。</li>
</ul>
<p>这个过程经过了四次上下文的切换，经过了四次数据的复制：从磁盘复制到内核缓冲区（DMA），内核缓冲区复制到用户缓冲区（CPU），从用户缓冲区到socket缓冲区（CPU），从socket缓冲区复制到网卡中（DMA）。</p>
<p>首先，期间共<strong>发生了 4 次用户态与内核态的上下文切换</strong>，因为发生了两次系统调用，一次是 <code>read()</code> ，一次是 <code>write()</code>，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。</p>
<p>上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。</p>
<p>其次，还<strong>发生了 4 次数据拷贝</strong>，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：</p>
<p>这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。</p>
<p>这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。</p>
<p>因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此<strong>用户的缓冲区是没有必要存在的</strong></p>
<blockquote>
<p>所以零拷贝技术不允许对数据进行加工，只能进行读取传输。</p>
</blockquote>
<p><strong>零拷贝技术实现方案一：mmap()系统调用：</strong></p>
<blockquote>
<p>需要注意的是，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送</p>
</blockquote>
<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap%20%2B%20write%20%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom:80%;">

<p><code>mmap()</code> 系统调用函数会直接把内核缓冲区里的数据「<strong>映射</strong>」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。</p>
<p>具体过程如下：</p>
<ul>
<li>应用进程调用了 <code>mmap()</code> 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，<strong>应用进程跟操作系统内核「共享」这个缓冲区</strong>；</li>
<li>应用进程再调用 <code>write()</code>，操作系统<strong>直接将内核缓冲区的数据拷贝到 socket 缓冲区中</strong>，这一切都发生在内核态，由 CPU 来搬运数据；</li>
<li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li>
</ul>
<blockquote>
<p>关键是理解mmap()系统调用，这个调用过程的结果是：用户进程和操作系统共享内核缓冲区的数据，相当于为用户进程打开了一扇窗口，用户进程能够看到这些数据，而不必再复制一份给用户缓冲区了。</p>
</blockquote>
<p>使用mmap()系统调用，只需要两次上下文切换，三次数据复制。</p>
<p>但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。</p>
<p><strong>零拷贝技术实现方案二：sendfile()：</strong></p>
<p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 <code>sendfile()</code>，函数形式如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">sendfile</span><span class="params">(<span class="type">int</span> out_fd, <span class="type">int</span> in_fd, <span class="type">off_t</span> *offset, <span class="type">size_t</span> count)</span>;</span><br></pre></td></tr></table></figure>



<p>它的前两个参数分别是<strong>目的端和源端的文件描述符</strong>，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p>
<p>首先，它可以替代前面的 <code>read()</code> 和 <code>write()</code> 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p>
<p>其次，该系统调用，可以<strong>直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝</strong>。如下图：</p>
<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom:75%;">

<blockquote>
<p>相较于方案一：减少了两次上下文切换。仍然需要三次数据拷贝。</p>
</blockquote>
<p><strong>方案三：进一步升级</strong></p>
<p>如果网卡支持 SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术（和普通的 DMA 有所不同）</p>
<ul>
<li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li>
<li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li>
</ul>
<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img" style="zoom:80%;">



<blockquote>
<p>相较于方案二：又减少了一次数据复制过程，只需要两次上下文切换，两次数据复制过程。 网卡的SG-DMA可以直接从内核缓冲区中得到数据。</p>
</blockquote>
<p>这就是所谓的<strong>零拷贝（*Zero-copy*）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</strong>。</p>
<p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</strong></p>
<p>所以，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong></p>
<p>事实上，<strong>Kafka 这个开源项目，就利用了==「零拷贝」==技术，</strong>从而大幅提升了 I/O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一。</p>
<p><strong>Nginx 也支持零拷贝技术</strong>，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率，是否开启零拷贝技术的配置如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">	sendfile on</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>sendfile 配置的具体意思:</p>
<ul>
<li>设置为 on 表示，使用零拷贝技术来传输文件：sendfile ，这样只需要 2 次上下文切换，和 2 次数据拷贝。</li>
<li>设置为 off 表示，使用传统的文件传输技术：read + write，这时就需要 4 次上下文切换，和 4 次数据拷贝。</li>
</ul>
<h4 id="IO-多路复用-select-poll-epoll"><a href="#IO-多路复用-select-poll-epoll" class="headerlink" title="IO 多路复用 select poll epoll"></a>IO 多路复用 select poll epoll</h4><p>我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，<strong>进程可以通过一个系统调用函数从内核中获取多个事件</strong>。</p>
<p>select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。</p>
<p>一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。</p>
<p>select 实现多路复用的方式是，将已连接的 Socket 都放到一个<strong>文件描述符集合</strong>，然后调用 select 函数将文件描述符集合<strong>拷贝</strong>到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合<strong>拷贝</strong>回用户态里，然后用户态还需要再通过<strong>遍历</strong>的方法找到可读或可写的 Socket，然后再对其处理。</p>
<p>所以，对于 select 这种方式，需要进行 <strong>2 次「遍历」文件描述符集合</strong>，一次是在内核态里，一个次是在用户态里 ，而且还会发生 <strong>2 次「拷贝」文件描述符集合</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p>
<p>poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制</p>
<p>epoll 通过两个方面，很好解决了 select/poll 的问题。</p>
<p><em>第一点</em>，epoll 在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的 socket 通过 <code>epoll_ctl()</code> 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 <code>O(logn)</code>。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。</p>
<p><em>第二点</em>， epoll 使用<strong>事件驱动</strong>的机制，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个 socket 有事件发生时，通过<strong>回调函数</strong>内核会将其加入到这个就绪事件列表中，当用户调用 <code>epoll_wait()</code> 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。</p>
<p>epoll 是解决 C10K 问题的利器，通过两个方面解决了 select/poll 的问题。</p>
<ul>
<li>epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。</li>
<li>epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。</li>
</ul>
<blockquote>
<p>select/poll : 基本没有区别，都是将监听的socket传到内核，内核遍历，标记有事件发生的socket再传到用户态，用户继续遍历。</p>
<p>select用的是bitmap, poll用的是动态数组，也就是链表的形式。</p>
<p>epoll的改进是在内核态中：维护了一个红黑树，每次用户态有socket只需要传入局部或者一个就行，而不用把所有的socket都传入到内核态中进行检测和验证。</p>
<p>红黑树的增删改都是O(logn)复杂度的。</p>
<p>epoll在内核里维护了一个链表来记录就绪事件。</p>
</blockquote>
<p>这个是定制监听事件的机制实现。通过 poll 机制让上层能直接告诉底层，我这个 fd 一旦读写就绪了，请底层硬件（比如网卡）回调的时候自动把这个 fd 相关的结构体放到指定队列中，并且唤醒操作系统。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/4UtmXsuLoNf8ibbmupPaBa0cF8gOxTvYtcH08gaf9bcOe0ibJGcK1utf6T50iclTtnj2DIlibdYSK35icnKaCYQu30g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>
<p>epoll 池只需要遍历这个就绪链表，就能给用户返回所有已经就绪的 fd 数组；</p>
<p>总结问题：</p>
<p>单核CPU能实现并行吗？　不能</p>
<p>单线程能实现高并发吗？　能</p>
<p>单线程如何做到高并发？　IO多路复用</p>
<p>单线程实现并发的例子： redis nginx</p>
<h4 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h4><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p><strong>（1）C/C++的编程思想和特性</strong>（面向对象；封装性、继承性、多态性，几个特性的原理要能口述）</p>
<p><strong>（2）面向对象与面向过程的区别？</strong></p>
<p>答：面向过程就是分析出解决问题所需要的步骤，然后用函数把这些步骤一步步实现，使用的时候一个个依次调用就可以了；面向对象是把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为。</p>
<p><strong>（3）引用传递与值传递的区别？</strong>（指针与引用的区别也需要去了解，这里只给出引用传递与值传递的区别）</p>
<p>答：值传递是指方法被调用时，实参通过形参把内容副本传入方法内部，此时形参接收的是实参的一个副本，在方法内对形参的任何操作不影响原始值的内容；引用传递指向真实内容的地址值，在方法调用时，实参的地址通过方法调用传递给被调用的对应的形参，对该形参的操作会影响原始值的内容。</p>
<blockquote>
<p>Java只有值传递</p>
</blockquote>
<p><strong>（4）静态函数是什么？什么情况下适合使用静态函数？</strong></p>
<p>答：静态函数是用static修饰符修饰的函数，静态函数只能访问静态变量。类中函数调用的结果不会访问或者修改任何对象数据成员的情况下适合使用静态函数。</p>
<p><strong>（5）什么是泛型编程？</strong></p>
<p>答：泛型编程指编写完全一般化并可重复使用的算法，其效率与针对某特定数据类型而设计的算法相同。所谓泛型是指具有在多种数据类型上皆可操作的含意。</p>
<p><strong>02 操作系统</strong></p>
<p><strong>1.计算机系统概述</strong></p>
<p><strong>（1）什么是操作系统（简称OS）？</strong></p>
<p>答：操作系统是指控制和管理整个计算机系统的硬件和软件资源，并合理的组织和调度计算机的工作和资源的分配，以提供给用户和其它软件方便的接口和环境，它是计算机系统中最基本的系统软件。</p>
<p><strong>（2）中断、异常的联系与区别？</strong></p>
<p>答：从发生源角度和处理方式角度划分为了中断和异常，但是他们处理问题的方式和思路本质是一样的。中断指I/O设备发出,也成为外中断，属于外部事件，是正在运行的程序所不期望的；异常是正在执行的指令引发的，是内中断,cpu执行指令本身出现问题/响应错误/异常处理程序,执行系统调用。</p>
<p><strong>（3）系统调用是什么？</strong></p>
<p>答：操作系统是使用硬件资源的唯一入口，而这个入口就是操作系统提供的系统调用。</p>
<p><strong>2.进程管理</strong></p>
<p><strong>（1）进程与线程</strong>（定义、通信方式、进程与线程的区别，考的几率较大，内容较多，需要认真掌握）</p>
<p><strong>（2）进程的5种状态及转换过程</strong></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/s7BcmxdBia9lqNYjVfmgGFicg3UDibUsfT1mCMCLtXgRvwAMwM9a7qvJCMRqP9ibC8ukIwJ5Xialxn8drL307nHzmEQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>
<p><strong>（3）进程的调度算法</strong>（最短作业优先、先来先服务、优先级调度算法、时间片轮转、最高响应比优先、多级反馈队列调度算法，这几种算法要大致知道原理）</p>
<p><strong>（4）同步和互斥分别是什么？</strong>（进程同步相关概念要掌握）</p>
<p>答：同步是多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态；互斥是多个进程在同一时刻只有一个进程能进入临界区。</p>
<p><strong>（5）饥饿与死锁的区别？</strong></p>
<p>答：饥饿是指一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态；死锁是指两个或两个以上的进程/线程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。</p>
<p><strong>（6）银行家算法如何解题？</strong></p>
<p>答：列出各个资源的剩余情况，再列出各个进程完成需要的资源情况，最后根据前两种情况判断哪个进程可以执行完，执行完进程后会释放资源，再重复以上步骤即可。</p>
<p><strong>3.内存管理</strong></p>
<p><strong>（1）将用户程序变为可在内存中执行的程序的步骤</strong>（编译、链接、装入，大致解释一下这三个步骤）</p>
<p><strong>（2）程序的装入方式有哪些</strong>（绝对装入、动态运行装入、可重定位装入，掌握原理）</p>
<p><strong>（3）内存连续分配管理方式有哪些</strong>（单一连续分配、固定分区分配、动态分区分配，掌握原理）</p>
<p><strong>（4）页面置换算法</strong>（最佳置换算法、先进先出置换算法、最近最久未使用算法、时钟置换算法，比较重要，掌握原理）</p>
<p><strong>4.文件管理</strong></p>
<p><strong>磁盘调度算法</strong>（先来先服务算法、最短寻道时间优先算法、扫描算法、循环扫描算法，比较重要，掌握原理）</p>
<p><strong>5.I/O管理</strong></p>
<p><strong>（1）I/O控制方式有哪些</strong>（程序 I/O 方式、中断驱动方式、DMA方式、I/O通道控制方式，比较重要，掌握原理）</p>
<p><strong>（2）解释一下Spooling技术</strong></p>
<p>答：Spooling技术能够缓和CPU和外设的速度，提高IO速度，将独占设备转化为共享设备，并实现虚拟设备功能。</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>zhu</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://github.com/sumilk-z/sumilk-z.github.io/2023/03/13/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/">https://github.com/sumilk-z/sumilk-z.github.io/2023/03/13/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>Do you believe in <strong>LIGHT</strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/basic/"># basic</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2023/03/13/%E5%9B%BE%E8%A7%A3TCPIP%E7%AC%94%E8%AE%B0/">计算机网络笔记——TCP/IP UDP</a>
            
            
            <a class="next" rel="next" href="/2023/03/12/redis%E7%AC%94%E8%AE%B0/">Redis持久化、过期删除、内存淘汰、缓存相关</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© zhu | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>